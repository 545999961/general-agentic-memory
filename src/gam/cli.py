# -*- coding: utf-8 -*-
"""
GAM CLI - Command Line Interface

æä¾›å‘½ä»¤è¡Œå·¥å…·ï¼š
- gam-add: å‘ GAM æ·»åŠ å†…å®¹ï¼ˆæ”¯æŒ text / video ä¸¤ç§ç±»å‹ï¼‰
- gam-request: åŸºäº GAM è¿›è¡Œé—®ç­”ï¼ˆæ”¯æŒ text / video ä¸¤ç§ç±»å‹ï¼‰
- gam-skill-prompt: è¾“å‡º Skill æè¿°æ–‡æœ¬ï¼ˆç”¨äºæ³¨å…¥åˆ°å…¶ä»– Agent çš„ system promptï¼‰

ä½¿ç”¨ç¤ºä¾‹:
    # æ·»åŠ æ–‡ä»¶åˆ° text GAM
    gam-add --type text --gam-dir ./my_gam --input paper.pdf

    # æ·»åŠ è§†é¢‘åˆ° video GAM
    gam-add --type video --gam-dir ./my_video_gam --input ./video_dir

    # åŸºäº text GAM é—®ç­”
    gam-request --type text --gam-dir ./my_gam --question "What is the main conclusion?"

    # åŸºäº video GAM é—®ç­”
    gam-request --type video --gam-dir ./my_video_gam --question "What happens in the video?"

    # è·å– skill prompt
    gam-skill-prompt --gam-dir ./my_gam
"""

from __future__ import annotations

import argparse
import os
import sys
from pathlib import Path
from typing import Optional


def _build_generator(args):
    """æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ„å»º GAM Agent Generator å®ä¾‹"""
    from .generators.openai_generator import OpenAIGenerator
    from .generators.config import OpenAIGeneratorConfig

    api_key = args.api_key or os.environ.get("OPENAI_API_KEY", "")
    if not api_key:
        print("Error: --api-key æˆ–ç¯å¢ƒå˜é‡ OPENAI_API_KEY å¿…é¡»æä¾›", file=sys.stderr)
        sys.exit(1)

    config = OpenAIGeneratorConfig(
        model_name=args.model,
        base_url=args.api_base,
        api_key=api_key,
        max_tokens=args.max_tokens,
        temperature=args.temperature,
    )
    return OpenAIGenerator(config)


def _build_chat_generator(args):
    """æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ„å»º Chat Agent Generator å®ä¾‹ï¼ˆå›é€€åˆ° GAM Agent é…ç½®ï¼‰"""
    chat_model = getattr(args, "chat_model", None)
    chat_api_base = getattr(args, "chat_api_base", None)
    chat_api_key = getattr(args, "chat_api_key", None)

    if not chat_model and not chat_api_base and not chat_api_key:
        return _build_generator(args)

    from .generators.openai_generator import OpenAIGenerator
    from .generators.config import OpenAIGeneratorConfig

    config = OpenAIGeneratorConfig(
        model_name=chat_model or args.model,
        base_url=chat_api_base or args.api_base,
        api_key=chat_api_key or args.api_key or os.environ.get("OPENAI_API_KEY", ""),
        max_tokens=args.max_tokens,
        temperature=args.temperature,
    )
    return OpenAIGenerator(config)


def _build_workspace(gam_dir: str):
    """æ„å»º LocalWorkspace"""
    from .workspaces.local_workspace import LocalWorkspace

    gam_path = Path(gam_dir).resolve()
    gam_path.mkdir(parents=True, exist_ok=True)
    return LocalWorkspace(root_path=str(gam_path))


def _build_tree(gam_dir: str, workspace):
    """æ„å»ºæˆ–åŠ è½½ GAMTree"""
    from .core.tree import GAMTree

    gam_path = Path(gam_dir).resolve()
    gam_path.mkdir(parents=True, exist_ok=True)

    try:
        tree = GAMTree.from_disk(gam_path, workspace)
    except Exception:
        tree = GAMTree.create(gam_path, name=gam_path.name)
    return tree


def _build_video_tree(gam_dir: str, workspace):
    """æ„å»ºæˆ–åŠ è½½ VideoGAMTree"""
    from .core.tree import VideoGAMTree

    gam_path = Path(gam_dir).resolve()
    gam_path.mkdir(parents=True, exist_ok=True)

    try:
        tree = VideoGAMTree.from_disk(gam_path, workspace)
    except Exception:
        tree = VideoGAMTree.create_empty(gam_path, name=gam_path.name)
    return tree


# ========== å…±äº«å‚æ•° ==========

def _add_common_args(parser: argparse.ArgumentParser):
    """æ·»åŠ é€šç”¨çš„ LLM/workspace å‚æ•°"""
    parser.add_argument(
        "--type", "-t",
        type=str,
        required=True,
        choices=["text", "video"],
        help="GAM ç±»å‹ï¼štextï¼ˆæ–‡æœ¬ï¼‰æˆ– videoï¼ˆè§†é¢‘ï¼‰",
    )
    parser.add_argument(
        "--gam-dir",
        type=str,
        required=True,
        help="GAM ç›®å½•è·¯å¾„ï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºï¼‰",
    )
    parser.add_argument(
        "--model",
        type=str,
        default=os.environ.get("GAM_MODEL", "gpt-4o-mini"),
        help="LLM æ¨¡å‹åç§°ï¼ˆé»˜è®¤: gpt-4o-miniï¼Œå¯é€šè¿‡ GAM_MODEL ç¯å¢ƒå˜é‡è®¾ç½®ï¼‰",
    )
    parser.add_argument(
        "--api-base",
        type=str,
        default=os.environ.get("GAM_API_BASE", "https://api.openai.com/v1"),
        help="API base URLï¼ˆé»˜è®¤: https://api.openai.com/v1ï¼Œå¯é€šè¿‡ GAM_API_BASE ç¯å¢ƒå˜é‡è®¾ç½®ï¼‰",
    )
    parser.add_argument(
        "--api-key",
        type=str,
        default=os.environ.get("GAM_API_KEY", os.environ.get("OPENAI_API_KEY", "")),
        help="API keyï¼ˆå¯é€šè¿‡ GAM_API_KEY æˆ– OPENAI_API_KEY ç¯å¢ƒå˜é‡è®¾ç½®ï¼‰",
    )
    parser.add_argument(
        "--max-tokens",
        type=int,
        default=int(os.environ.get("GAM_MAX_TOKENS", "4096")),
        help="LLM æœ€å¤§ç”Ÿæˆ token æ•°ï¼ˆé»˜è®¤: 4096ï¼‰",
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=float(os.environ.get("GAM_TEMPERATURE", "0.3")),
        help="LLM æ¸©åº¦ï¼ˆé»˜è®¤: 0.3ï¼‰",
    )
    parser.add_argument(
        "--verbose",
        action=argparse.BooleanOptionalAction,
        default=True,
        help="æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼ˆé»˜è®¤: å¼€å¯ï¼‰",
    )


# ========== gam-add ==========

def cli_add():
    """
    CLI å…¥å£: gam-add

    æ ¹æ® --type å‚æ•°é€‰æ‹©æ·»åŠ æ–‡æœ¬æˆ–è§†é¢‘å†…å®¹åˆ° GAM çŸ¥è¯†åº“ã€‚
    """
    parser = argparse.ArgumentParser(
        prog="gam-add",
        description="å‘ GAM çŸ¥è¯†åº“æ·»åŠ å†…å®¹ï¼ˆæ”¯æŒ text / videoï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""\
ç¤ºä¾‹:
  # æ·»åŠ å•ä¸ªæ–‡ä»¶ï¼ˆtextï¼‰
  gam-add --type text --gam-dir ./my_gam --input paper.pdf

  # æ·»åŠ å¤šä¸ªæ–‡ä»¶
  gam-add --type text --gam-dir ./my_gam --input paper1.pdf --input paper2.txt

  # æ·»åŠ æ–‡æœ¬å†…å®¹
  gam-add --type text --gam-dir ./my_gam --content "Some text to remember"

  # åŒæ—¶æ·»åŠ æ–‡ä»¶å’Œæ–‡æœ¬
  gam-add --type text --gam-dir ./my_gam --input paper.pdf --content "Additional notes"

  # ä¸åˆ†å—ï¼Œå°†æ¯ä¸ªè¾“å…¥ä½œä¸ºæ•´ä½“
  gam-add --type text --gam-dir ./my_gam --input paper.pdf --no-chunking

  # æ·»åŠ è§†é¢‘
  gam-add --type video --gam-dir ./my_video_gam --input ./video_dir

  # è§†é¢‘ï¼šæŒ‡å®š segmentor ä½¿ç”¨ä¸åŒæ¨¡å‹
  gam-add --type video --gam-dir ./my_video_gam --input ./video_dir \\
      --model gpt-4o --segmentor-model gpt-4o-mini

  # è§†é¢‘ï¼šä¸ä½¿ç”¨å­—å¹•è¿›è¡Œæè¿°ç”Ÿæˆ
  gam-add --type video --gam-dir ./my_video_gam --input ./video_dir --no-caption-subtitles
""",
    )

    _add_common_args(parser)

    # text add å‚æ•°
    parser.add_argument(
        "--input", "-i",
        type=str,
        action="append",
        default=None,
        help="è¾“å…¥æ–‡ä»¶/ç›®å½•è·¯å¾„ï¼ˆå¯å¤šæ¬¡æŒ‡å®šï¼›text ç±»å‹ä¸ºæ–‡ä»¶è·¯å¾„ï¼Œvideo ç±»å‹ä¸ºè§†é¢‘ç›®å½•è·¯å¾„ï¼‰",
    )
    parser.add_argument(
        "--content", "-c",
        type=str,
        action="append",
        default=None,
        help="[text] ç›´æ¥è¾“å…¥æ–‡æœ¬å†…å®¹ï¼ˆå¯å¤šæ¬¡æŒ‡å®šï¼‰",
    )
    parser.add_argument(
        "--context",
        type=str,
        default="",
        help="[text] å¯é€‰çš„ä¸Šä¸‹æ–‡/è¯´æ˜ä¿¡æ¯",
    )
    parser.add_argument(
        "--chunking",
        dest="use_chunking",
        action=argparse.BooleanOptionalAction,
        default=True,
        help="[text] æ˜¯å¦å¯ç”¨æ™ºèƒ½åˆ†å—ï¼ˆé»˜è®¤: å¼€å¯ï¼‰",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="[text] å¯é€‰ï¼šä¿å­˜åŸå§‹ chunk çš„ç›®å½•",
    )
    parser.add_argument(
        "--force-reorganize",
        action="store_true",
        default=False,
        help="[text] å¼ºåˆ¶è§¦å‘ç›®å½•ç»“æ„é‡ç»„",
    )
    parser.add_argument(
        "--memory-workers",
        type=int,
        default=4,
        help="[text] å¹¶è¡Œç”Ÿæˆ memory çš„å·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 4ï¼‰",
    )

    # video add å‚æ•°
    parser.add_argument(
        "--segmentor-model",
        type=str,
        default=None,
        help="[video] Segmentor LLM æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä¸ --model ç›¸åŒï¼‰",
    )
    parser.add_argument(
        "--segmentor-api-base",
        type=str,
        default=None,
        help="[video] Segmentor API base URLï¼ˆé»˜è®¤ä¸ --api-base ç›¸åŒï¼‰",
    )
    parser.add_argument(
        "--segmentor-api-key",
        type=str,
        default=None,
        help="[video] Segmentor API keyï¼ˆé»˜è®¤ä¸ --api-key ç›¸åŒï¼‰",
    )
    parser.add_argument(
        "--caption-subtitles",
        dest="caption_with_subtitles",
        action=argparse.BooleanOptionalAction,
        default=True,
        help="[video] æè¿°ç”Ÿæˆæ—¶æ˜¯å¦åŒ…å«å­—å¹•ä¿¡æ¯ï¼ˆé»˜è®¤: å¼€å¯ï¼‰",
    )

    args = parser.parse_args()

    if args.type == "text":
        _do_text_add(args, parser)
    else:
        _do_video_add(args, parser)


def _do_text_add(args, parser):
    """æ‰§è¡Œ text add é€»è¾‘"""
    if not args.input and not args.content:
        parser.error("text ç±»å‹è‡³å°‘éœ€è¦æä¾› --input æˆ– --content")

    generator = _build_generator(args)
    workspace = _build_workspace(args.gam_dir)
    tree = _build_tree(args.gam_dir, workspace)

    from .agents.text_gam_agent import TextGAMAgent

    agent = TextGAMAgent(
        generator=generator,
        tree=tree,
        workspace=workspace,
        use_chunking=args.use_chunking,
        auto_save=True,
        verbose=args.verbose,
        memory_workers=args.memory_workers,
    )

    input_files = [Path(f) for f in args.input] if args.input else None
    contents = args.content if args.content else None

    result = agent.add(
        input_file=input_files,
        content=contents,
        context=args.context,
        output_dir=args.output_dir,
        force_reorganize=args.force_reorganize,
    )

    if args.verbose:
        print(f"\n{'='*60}")
        print("âœ… gam-add (text) å®Œæˆ!")
        print(f"GAM ç›®å½•: {Path(args.gam_dir).resolve()}")
        if hasattr(result, 'created_files'):
            print(f"åˆ›å»ºæ–‡ä»¶æ•°: {len(result.created_files)}")
        if hasattr(result, 'new_directories'):
            print(f"æ–°å»ºç›®å½•æ•°: {len(result.new_directories)}")
        print(f"{'='*60}\n")


def _do_video_add(args, parser):
    """æ‰§è¡Œ video add é€»è¾‘"""
    if not args.input:
        parser.error("video ç±»å‹éœ€è¦æä¾› --inputï¼ˆè§†é¢‘ç›®å½•è·¯å¾„ï¼‰")
    if len(args.input) > 1:
        parser.error("video ç±»å‹ä»…æ”¯æŒä¸€ä¸ª --inputï¼ˆè§†é¢‘ç›®å½•è·¯å¾„ï¼‰")

    generator = _build_generator(args)

    if args.segmentor_model:
        from .generators.openai_generator import OpenAIGenerator
        from .generators.config import OpenAIGeneratorConfig

        seg_config = OpenAIGeneratorConfig(
            model_name=args.segmentor_model,
            base_url=args.segmentor_api_base or args.api_base,
            api_key=args.segmentor_api_key or args.api_key or os.environ.get("OPENAI_API_KEY", ""),
            max_tokens=args.max_tokens,
            temperature=args.temperature,
        )
        segmentor = OpenAIGenerator(seg_config)
    else:
        segmentor = generator

    workspace = _build_workspace(args.gam_dir)
    tree = _build_video_tree(args.gam_dir, workspace)

    from .agents.video_gam_agent import VideoGAMAgent

    agent = VideoGAMAgent(
        planner=generator,
        segmentor=segmentor,
        workspace=workspace,
        tree=tree,
    )

    input_path = Path(args.input[0]).resolve()
    result = agent.add(
        input_path=input_path,
        verbose=args.verbose,
        caption_with_subtitles=args.caption_with_subtitles,
    )

    if args.verbose:
        print(f"\n{'='*60}")
        print("âœ… gam-add (video) å®Œæˆ!")
        print(f"GAM ç›®å½•: {Path(args.gam_dir).resolve()}")
        print(f"è§†é¢‘åˆ†æ®µæ•°: {result.segment_num}")
        print(f"{'='*60}\n")


# ========== gam-request ==========

def cli_request():
    """
    CLI å…¥å£: gam-request

    æ ¹æ® --type å‚æ•°é€‰æ‹©åŸºäºæ–‡æœ¬æˆ–è§†é¢‘ GAM è¿›è¡Œé—®ç­”ã€‚
    """
    parser = argparse.ArgumentParser(
        prog="gam-request",
        description="åŸºäº GAM çŸ¥è¯†åº“è¿›è¡Œé—®ç­”ï¼ˆæ”¯æŒ text / videoï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""\
ç¤ºä¾‹:
  # text åŸºæœ¬é—®ç­”
  gam-request --type text --gam-dir ./my_gam --question "What is the main conclusion?"

  # text æŒ‡å®šç³»ç»Ÿæç¤º
  gam-request --type text --gam-dir ./my_gam -q "Summarize" --system-prompt "You are a research assistant."

  # text å¢åŠ æ¢ç´¢è½®æ•°
  gam-request --type text --gam-dir ./my_gam -q "è¯¦ç»†åˆ†æå®éªŒç»“æœ" --max-iter 20

  # video åŸºæœ¬é—®ç­”
  gam-request --type video --gam-dir ./my_video_gam --question "What happens in the video?"

  # video ä½¿ç”¨ä¸“é—¨çš„è§†è§‰åˆ†ææ¨¡å‹
  gam-request --type video --gam-dir ./my_video_gam -q "Describe the scene" \\
      --video-model gpt-4o

  # video è°ƒæ•´è§†é¢‘åˆ†æå‚æ•°
  gam-request --type video --gam-dir ./my_video_gam -q "What color is the car?" \\
      --video-fps 2.0 --video-max-resolution 720

  # è¾“å‡º JSON æ ¼å¼ï¼ˆtext / video å‡æ”¯æŒï¼‰
  gam-request --type text --gam-dir ./my_gam -q "What methods were used?" --json
""",
    )

    _add_common_args(parser)

    # Chat Agent é…ç½®ï¼ˆå¯å•ç‹¬æŒ‡å®šï¼Œé»˜è®¤å›é€€åˆ° GAM Agent é…ç½®ï¼‰
    parser.add_argument(
        "--chat-model",
        type=str,
        default=os.environ.get("GAM_CHAT_MODEL"),
        help="Chat Agent LLM æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä¸ --model ç›¸åŒï¼Œå¯é€šè¿‡ GAM_CHAT_MODEL ç¯å¢ƒå˜é‡è®¾ç½®ï¼‰",
    )
    parser.add_argument(
        "--chat-api-base",
        type=str,
        default=os.environ.get("GAM_CHAT_API_BASE"),
        help="Chat Agent API base URLï¼ˆé»˜è®¤ä¸ --api-base ç›¸åŒï¼Œå¯é€šè¿‡ GAM_CHAT_API_BASE ç¯å¢ƒå˜é‡è®¾ç½®ï¼‰",
    )
    parser.add_argument(
        "--chat-api-key",
        type=str,
        default=os.environ.get("GAM_CHAT_API_KEY"),
        help="Chat Agent API keyï¼ˆé»˜è®¤ä¸ --api-key ç›¸åŒï¼Œå¯é€šè¿‡ GAM_CHAT_API_KEY ç¯å¢ƒå˜é‡è®¾ç½®ï¼‰",
    )

    # å…±äº« request å‚æ•°
    parser.add_argument(
        "--question", "-q",
        type=str,
        required=True,
        help="ç”¨æˆ·é—®é¢˜",
    )
    parser.add_argument(
        "--system-prompt", "-s",
        type=str,
        default="",
        help="ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰",
    )
    parser.add_argument(
        "--max-iter",
        type=int,
        default=10,
        help="æœ€å¤§æ¢ç´¢è¿­ä»£è½®æ•°ï¼ˆé»˜è®¤: 10ï¼‰",
    )
    parser.add_argument(
        "--json",
        action="store_true",
        default=False,
        help="ä»¥ JSON æ ¼å¼è¾“å‡ºå®Œæ•´ç»“æœ",
    )

    # video request ç‰¹æœ‰å‚æ•°
    parser.add_argument(
        "--video-model",
        type=str,
        default=None,
        help="[video] å¤šæ¨¡æ€è§†è§‰åˆ†æ LLM æ¨¡å‹åç§°ï¼ˆç”¨äº inspect_video å·¥å…·ï¼Œé»˜è®¤ä¸ --model ç›¸åŒï¼‰",
    )
    parser.add_argument(
        "--video-api-base",
        type=str,
        default=None,
        help="[video] å¤šæ¨¡æ€è§†è§‰åˆ†æ LLM API base URLï¼ˆé»˜è®¤ä¸ --api-base ç›¸åŒï¼‰",
    )
    parser.add_argument(
        "--video-api-key",
        type=str,
        default=None,
        help="[video] å¤šæ¨¡æ€è§†è§‰åˆ†æ LLM API keyï¼ˆé»˜è®¤ä¸ --api-key ç›¸åŒï¼‰",
    )
    parser.add_argument(
        "--video-fps",
        type=float,
        default=1.0,
        help="[video] è§†é¢‘åˆ†æé‡‡æ ·å¸§ç‡ï¼ˆé»˜è®¤: 1.0 fpsï¼‰",
    )
    parser.add_argument(
        "--video-max-resolution",
        type=int,
        default=480,
        help="[video] è§†é¢‘åˆ†ææœ€å¤§åˆ†è¾¨ç‡ï¼ˆé»˜è®¤: 480ï¼‰",
    )

    args = parser.parse_args()

    if args.type == "text":
        _do_text_request(args)
    else:
        _do_video_request(args)


def _do_text_request(args):
    """æ‰§è¡Œ text request é€»è¾‘"""
    chat_gen = _build_chat_generator(args)
    workspace = _build_workspace(args.gam_dir)
    tree = _build_tree(args.gam_dir, workspace)

    from .agents.text_chat_agent import TextChatAgent

    agent = TextChatAgent(
        generator=chat_gen,
        tree=tree,
        workspace=workspace,
        max_iterations=args.max_iter,
        verbose=args.verbose,
    )

    result = agent.request(
        system_prompt=args.system_prompt,
        user_prompt=args.question,
        max_iter=args.max_iter,
    )

    _print_request_result(result, args)


def _do_video_request(args):
    """æ‰§è¡Œ video request é€»è¾‘"""
    chat_gen = _build_chat_generator(args)

    if args.video_model:
        from .generators.openai_generator import OpenAIGenerator
        from .generators.config import OpenAIGeneratorConfig

        video_config = OpenAIGeneratorConfig(
            model_name=args.video_model,
            base_url=args.video_api_base or args.api_base,
            api_key=args.video_api_key or args.api_key or os.environ.get("OPENAI_API_KEY", ""),
            max_tokens=args.max_tokens,
            temperature=args.temperature,
        )
        video_generator = OpenAIGenerator(video_config)
    else:
        video_generator = None

    workspace = _build_workspace(args.gam_dir)
    tree = _build_video_tree(args.gam_dir, workspace)

    from .agents.video_chat_agent import VideoChatAgent

    agent = VideoChatAgent(
        generator=chat_gen,
        tree=tree,
        workspace=workspace,
        video_generator=video_generator,
        max_iterations=args.max_iter,
        verbose=args.verbose,
        video_fps=args.video_fps,
        video_max_resolution=args.video_max_resolution,
    )

    result = agent.request(
        system_prompt=args.system_prompt,
        user_prompt=args.question,
        max_iter=args.max_iter,
    )

    _print_request_result(result, args)


def _print_request_result(result, args):
    """ç»Ÿä¸€çš„ request ç»“æœè¾“å‡º"""
    if args.json:
        import json
        output = {
            "question": result.question,
            "answer": result.answer,
            "sources": result.sources,
            "confidence": result.confidence,
            "notes": result.notes,
            "files_read": result.files_read,
            "dirs_explored": result.dirs_explored,
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
    else:
        print(f"\n{'='*60}")
        print(f"ğŸ“ é—®é¢˜: {result.question}")
        print(f"{'='*60}")
        print(f"\nğŸ’¡ å›ç­”:\n{result.answer}")
        if result.sources:
            print(f"\nğŸ“š æ¥æº: {', '.join(result.sources)}")
        if result.confidence:
            print(f"\nğŸ¯ ç½®ä¿¡åº¦: {result.confidence}")
        print(f"\n{'='*60}")


# ========== gam-skill-prompt ==========

def cli_skill_prompt():
    """
    CLI å…¥å£: gam-skill-prompt

    è¾“å‡º GAM çš„ Skill æè¿°æ–‡æœ¬ï¼Œå¯ç›´æ¥æ³¨å…¥åˆ°å…¶ä»– Agent çš„ system prompt ä¸­ã€‚
    """
    parser = argparse.ArgumentParser(
        prog="gam-skill-prompt",
        description="è¾“å‡º GAM Skill æè¿°æ–‡æœ¬ï¼ˆç”¨äºæ³¨å…¥åˆ° Agent system promptï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""\
ç¤ºä¾‹:
  # è¾“å‡º skill promptï¼ˆç›´æ¥æ‰“å°åˆ°ç»ˆç«¯ï¼‰
  gam-skill-prompt

  # æŒ‡å®š GAM ç›®å½•ï¼ˆä¼šæ›¿æ¢åˆ°ç¤ºä¾‹ä¸­çš„è·¯å¾„ï¼‰
  gam-skill-prompt --gam-dir ./my_gam

  # ä¿å­˜åˆ°æ–‡ä»¶
  gam-skill-prompt --gam-dir ./my_gam > skill.txt

  # åœ¨ Python ä¸­ä½¿ç”¨
  # from gam import get_skill_prompt
  # skill = get_skill_prompt(gam_dir="./my_gam")
  # system_prompt = f"You are a research agent.\\n\\n{skill}"
""",
    )

    parser.add_argument(
        "--gam-dir",
        type=str,
        default="/path/to/gam",
        help="GAM ç›®å½•è·¯å¾„ï¼ˆä¼šæ›¿æ¢åˆ° skill prompt ä¸­çš„ç¤ºä¾‹è·¯å¾„ï¼Œé»˜è®¤: /path/to/gamï¼‰",
    )

    args = parser.parse_args()

    from .prompts.skill_prompts import get_skill_prompt
    print(get_skill_prompt(gam_dir=args.gam_dir))
