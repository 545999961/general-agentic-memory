# -*- coding: utf-8 -*-
"""
GAM Web Application

A Flask-based web interface for building, managing and browsing GAM.

Uses TextGAMAgent for chunking and organizing content.
Uses TextChatAgent for Q&A over the GAM knowledge base.
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import Dict

from flask import Flask

from .helpers import DEFAULT_OUTPUT_BASE
from .routes import (
    browse_bp,
    pages_bp,
    pipeline_bp,
    research_bp,
    video_pipeline_bp,
    video_research_bp,
    long_horizontal_bp,
    custom_api_bp,
)


def create_app(
    generator=None,
    video_generator=None,
    segmentor=None,
    output_base: str = "",
) -> Flask:
    """
    åˆ›å»º Flask åº”ç”¨

    Args:
        generator: LLM generator å®ä¾‹ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™æ”¯æŒè‡ªåŠ¨ç»„ç»‡ï¼‰
        video_generator: å¤šæ¨¡æ€ LLM generatorï¼ˆç”¨äº VideoChatAgent çš„ inspect_videoï¼Œå¯é€‰ï¼‰
        segmentor: è§†é¢‘ç‰‡æ®µæè¿° LLM generatorï¼ˆç”¨äº VideoGAMAgent çš„ segmentorï¼Œå¯é€‰ï¼‰
        output_base: Pipeline è¾“å‡ºæ ¹ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ DEFAULT_OUTPUT_BASEï¼‰
    """
    app = Flask(
        __name__,
        template_folder=os.path.join(os.path.dirname(__file__), "templates"),
        static_folder=os.path.join(os.path.dirname(__file__), "static"),
    )
    app.config["MAX_CONTENT_LENGTH"] = 500 * 1024 * 1024  # 500MB max (for video)

    # Store shared state in app config
    app.config["GENERATOR"] = generator
    app.config["VIDEO_GENERATOR"] = video_generator
    app.config["SEGMENTOR"] = segmentor
    app.config["OUTPUT_BASE"] = output_base or DEFAULT_OUTPUT_BASE
    app.config["GAM_CACHE"]: Dict = {}

    # Register blueprints â€“ text
    app.register_blueprint(pages_bp)
    app.register_blueprint(pipeline_bp)
    app.register_blueprint(browse_bp)
    app.register_blueprint(research_bp)

    # Register blueprints â€“ video
    app.register_blueprint(video_pipeline_bp)
    app.register_blueprint(video_research_bp)

    # Register blueprints â€“ long horizontal
    app.register_blueprint(long_horizontal_bp)

    # Register blueprints â€“ custom api
    app.register_blueprint(custom_api_bp)

    return app


def run_server(
    generator=None,
    video_generator=None,
    segmentor=None,
    output_base: str = "",
    host: str = "0.0.0.0",
    port: int = 5000,
    debug: bool = True,
):
    """
    è¿è¡Œ GAM Web å¹³å°

    Args:
        generator: LLM generator å®ä¾‹ï¼ˆå¿…éœ€ï¼Œç”¨äº TextGAMAgent / TextChatAgent / VideoGAMAgentï¼‰
        video_generator: å¤šæ¨¡æ€ LLM generatorï¼ˆç”¨äº VideoChatAgent çš„ inspect_videoï¼Œå¯é€‰ï¼‰
        segmentor: è§†é¢‘ç‰‡æ®µæè¿° LLM generatorï¼ˆç”¨äº VideoGAMAgent çš„ segmentorï¼Œå¯é€‰ï¼‰
        output_base: Pipeline è¾“å‡ºæ ¹ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ DEFAULT_OUTPUT_BASEï¼‰
        host: ä¸»æœºåœ°å€
        port: ç«¯å£å·
        debug: æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼
    """
    app = create_app(
        generator=generator,
        video_generator=video_generator,
        segmentor=segmentor,
        output_base=output_base,
    )
    actual_output_base = app.config["OUTPUT_BASE"]

    print(f"\n{'='*60}")
    print(f"ğŸ§  GAM Platform - Text & Video Pipeline")
    print(f"{'='*60}")
    print(f"")
    print(f"ğŸ”— Text Platform: http://{host}:{port}/")
    print(f"ğŸ¬ Video Platform: http://{host}:{port}/video")
    print(f"ğŸ”„ Long Horizontal: http://{host}:{port}/long-horizontal")
    print(f"")
    print(f"ğŸ“¦ Default output: {actual_output_base}/[timestamp]/")
    print(f"   â”œâ”€â”€ chunks_*/  # TextGAMAgent chunks è¾“å‡º")
    print(f"   â”œâ”€â”€ gam/       # TextGAMAgent GAM è¾“å‡º")
    print(f"   â””â”€â”€ video_*/   # VideoGAMAgent è¾“å‡º")
    print(f"")
    if generator:
        print(f"âœ… LLM enabled: Full pipeline available")
        print(f"   - TextGAMAgent: æ™ºèƒ½æ–‡æœ¬åˆ‡åˆ† + ç›®å½•ç»„ç»‡")
        print(f"   - TextChatAgent: æ™ºèƒ½æ–‡æœ¬é—®ç­”")
        print(f"   - VideoGAMAgent: è§†é¢‘åˆ†æ + GAM æ„å»º")
        print(f"   - VideoChatAgent: è§†é¢‘çŸ¥è¯†åº“é—®ç­”")
    else:
        print(f"âš ï¸  No LLM configured!")
        print(f"   Pipeline requires an LLM generator.")
        print(f"   Please provide a generator when calling run_server().")
    print(f"")
    print(f"Press Ctrl+C to stop.")
    print(f"{'='*60}\n")

    app.run(host=host, port=port, debug=debug)


if __name__ == "__main__":
    # å°è¯•å¯¼å…¥ generatorï¼ˆéœ€è¦ç”¨æˆ·é…ç½®ï¼‰
    generator = None
    try:
        from gam.generators.openai_generator import OpenAIGenerator
        from gam.generators.config import OpenAIGeneratorConfig

        # è¿™é‡Œå¯ä»¥ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            config = OpenAIGeneratorConfig(api_key=api_key)
            generator = OpenAIGenerator(config)
            print("âœ… Using OpenAI generator from environment variable")
        else:
            print("âš ï¸  OPENAI_API_KEY not found in environment variables")
            print("   Running without LLM generator. Some features will be unavailable.")
    except Exception as e:
        print(f"âš ï¸  Could not initialize generator: {e}")
        print("   Running without LLM generator. Some features will be unavailable.")

    # è¿è¡ŒæœåŠ¡å™¨
    run_server(generator=generator)
