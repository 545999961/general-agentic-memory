#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Video GAM â€” Request (Q&A) Example

ä½¿ç”¨ Workflow("video") å¯¹å·²æ„å»ºçš„ Video GAM è¿›è¡Œé—®ç­”ã€‚

Usage:
    python request.py [gam_path] [question]

Examples:
    python request.py                                                          # ä½¿ç”¨é»˜è®¤è·¯å¾„å’Œé—®é¢˜
    python request.py ./output/chunk_build_gam                                 # æŒ‡å®š GAM è·¯å¾„
    python request.py ./output/chunk_build_gam "è§†é¢‘ä¸­å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ"                # æŒ‡å®šè·¯å¾„å’Œé—®é¢˜
"""

import sys
from pathlib import Path
from datetime import datetime

from gam import Workflow


def main():
    # ----------------------------------------------------------------
    # 1. è§£æå‚æ•°
    # ----------------------------------------------------------------
    default_gam = Path(__file__).parent / "output" / "chunk_build_gam"
    default_question = "æ€»ç»“ä¸€ä¸‹è¿™ä¸ªè§†é¢‘çš„ä¸»è¦å†…å®¹ã€‚"

    gam_path = Path(sys.argv[1]) if len(sys.argv) > 1 else default_gam
    question = " ".join(sys.argv[2:]) if len(sys.argv) > 2 else default_question

    if not gam_path.exists():
        print(f"âŒ GAM ä¸å­˜åœ¨: {gam_path}")
        print(f"\nUsage: python {Path(__file__).name} [gam_path] [question]")
        print(f"ğŸ’¡ æç¤º: è¯·å…ˆä½¿ç”¨ add.py æ„å»º Video GAM")
        return

    # ----------------------------------------------------------------
    # 2. åˆ›å»º Workflow  (åªéœ€è¦è¿™ä¸€æ­¥ï¼)
    # ----------------------------------------------------------------
    wf = Workflow(
        "video",
        gam_dir=gam_path,
        # LLM config â€” set via env vars GAM_MODEL, GAM_API_BASE, GAM_API_KEY
        # or pass explicitly here:
        # model="gpt-4o",
        # api_base="https://api.openai.com/v1",
        # api_key="sk-xxx",
        max_tokens=4096,
        temperature=0.3,
        # video_model="gpt-4o",
        # video_api_base="https://api.openai.com/v1",
        video_fps=1.0,
        video_max_resolution=480,
        max_iterations=20,
        verbose=True,
    )

    print(f"ğŸ“‚ GAM è·¯å¾„: {gam_path}")
    print(f"ğŸ¤– æ¨¡å‹: {wf.model}")
    print(f"\nğŸ“‚ GAM ç»“æ„:")
    print(wf.get_tree_view(depth=3))
    print(f"\nğŸ“‹ é—®é¢˜: {question}\n")

    # ----------------------------------------------------------------
    # 3. é—®ç­”
    # ----------------------------------------------------------------
    start = datetime.now()
    result = wf.request(question)
    duration = (datetime.now() - start).total_seconds()

    # ----------------------------------------------------------------
    # 4. æ˜¾ç¤ºç»“æœ
    # ----------------------------------------------------------------
    print("\n" + "=" * 80)
    print("ğŸ“ ç­”æ¡ˆ:")
    print("=" * 80)
    print(result.answer or "(æœªç”Ÿæˆç­”æ¡ˆ)")
    print("=" * 80)

    print(f"\nğŸ“š æ¥æº ({len(result.sources)}):")
    for i, src in enumerate(result.sources, 1):
        print(f"   {i}. {src}")

    print(f"\nğŸ“– è¯»å–çš„æ–‡ä»¶ ({len(result.files_read)}):")
    for i, f in enumerate(result.files_read, 1):
        print(f"   {i}. {f}")

    if hasattr(result, "confidence"):
        print(f"\nâœ… ç½®ä¿¡åº¦: {result.confidence:.2%}")

    print(f"\nâ±ï¸  è€—æ—¶: {duration:.2f} ç§’")


if __name__ == "__main__":
    main()
